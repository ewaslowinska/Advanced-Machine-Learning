{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "### Multiclass Classification\n",
    "I edited the code from Part 2 to conduct a multiclass classification on the dataset of cats, horses and dogs images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 16:41:38.212005: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoImageProcessor\n",
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "from transformers import DefaultDataCollator\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "from pycocotools.coco import COCO\n",
    "import random\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=203.98s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco = COCO(annotation_file=\"instances_train2017.json\")\n",
    "cat_cat = coco.getCatIds(catNms=\"cat\")\n",
    "horse_cat = coco.getCatIds(catNms=\"horse\")\n",
    "dog_cat = coco.getCatIds(catNms=\"dog\")\n",
    "cat_imgs = coco.getImgIds(catIds=cat_cat)\n",
    "horse_imgs = coco.getImgIds(catIds=horse_cat)\n",
    "dog_imgs = coco.getImgIds(catIds=dog_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "random.shuffle(cat_imgs)\n",
    "cat_imgs_train = cat_imgs[:400]\n",
    "cat_imgs_test = cat_imgs[400:600]\n",
    "\n",
    "random.shuffle(horse_imgs)\n",
    "horse_imgs_train = horse_imgs[:400]\n",
    "horse_imgs_test = horse_imgs[400:600]\n",
    "\n",
    "random.shuffle(dog_imgs)\n",
    "dog_imgs_train = dog_imgs[:400]\n",
    "dog_imgs_test = dog_imgs[400:600]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "cat_meta_train = coco.loadImgs(ids=cat_imgs_train)\n",
    "cat_meta_test = coco.loadImgs(ids=cat_imgs_test)\n",
    "horse_meta_train = coco.loadImgs(ids=horse_imgs_train)\n",
    "horse_meta_test = coco.loadImgs(ids=horse_imgs_test)\n",
    "dog_meta_train = coco.loadImgs(ids=dog_imgs_train)\n",
    "dog_meta_test = coco.loadImgs(ids=dog_imgs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def clean_data(meta, datadir=\"train2017\"):\n",
    "    return [x for x in meta if os.path.isfile(\"{}/{}\".format(datadir, x['file_name']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "cat_cleaned_train = clean_data(cat_meta_train)\n",
    "cat_cleaned_test = clean_data(cat_meta_test)\n",
    "horse_cleaned_train = clean_data(horse_meta_train)\n",
    "horse_cleaned_test = clean_data(horse_meta_test)\n",
    "dog_cleaned_train = clean_data(dog_meta_train)\n",
    "dog_cleaned_test = clean_data(dog_meta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(meta, datadir=\"train2017\"):\n",
    "    return [(x['file_name'], Image.open(\"{}/{}\".format(datadir, x['file_name'])).resize((100, 100))) for x in meta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "cat_data_train = get_data(cat_cleaned_train)\n",
    "horse_data_train = get_data(horse_cleaned_train)\n",
    "dog_data_train = get_data(dog_cleaned_train)\n",
    "cat_data_test = get_data(cat_cleaned_test)\n",
    "horse_data_test = get_data(horse_cleaned_test)\n",
    "dog_data_test = get_data(dog_cleaned_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "label2id = {'cat': '1', 'horse': '0', 'dog': '2'}\n",
    "id2label = {'1': 'cat', '0': 'horse', '2': 'dog'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "cat_data_train_df = pd.DataFrame(cat_data_train)\n",
    "cat_data_train_df['class'] = 'cat'\n",
    "horse_data_train_df = pd.DataFrame(horse_data_train)\n",
    "horse_data_train_df['class'] = 'horse'\n",
    "dog_data_train_df = pd.DataFrame(dog_data_train)\n",
    "dog_data_train_df['class'] = 'dog'\n",
    "cat_data_test_df = pd.DataFrame(cat_data_test)\n",
    "cat_data_test_df['class'] = 'cat'\n",
    "horse_data_test_df = pd.DataFrame(horse_data_test)\n",
    "horse_data_test_df['class'] = 'horse'\n",
    "dog_data_test_df = pd.DataFrame(dog_data_test)\n",
    "dog_data_test_df['class'] = 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([cat_data_train_df, horse_data_train_df, dog_data_train_df])\n",
    "test_df = pd.concat([cat_data_test_df, horse_data_test_df, dog_data_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_df['imgs'] = train_df[1].apply(lambda x: x.convert('RGB'))\n",
    "test_df['imgs'] = test_df[1].apply(lambda x: x.convert('RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_X = [x for x in train_df['imgs']]\n",
    "test_X = [x for x in test_df['imgs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_y = [1 if x == 'cat' else 0 if x == 'horse' else 2 for x in train_df['class']]\n",
    "test_y = [1 if x == 'cat' else 0 if x == 'horse' else 2 for x in test_df['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_data_zip = list(zip(train_X, train_y))\n",
    "test_data_zip = list(zip(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_image_list = []\n",
    "train_label_list = []\n",
    "test_image_list = []\n",
    "test_label_list = []\n",
    "train_dataset = {}\n",
    "test_dataset = {}\n",
    "for image, label in train_data_zip:\n",
    "    train_image_list.append(image)\n",
    "    train_label_list.append(label)\n",
    "for image, label in test_data_zip:\n",
    "    test_image_list.append(image)\n",
    "    test_label_list.append(label)\n",
    "train_dataset['image'] = train_image_list\n",
    "train_dataset['label'] = train_label_list\n",
    "test_dataset['image'] = test_image_list\n",
    "test_dataset['label'] = test_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_data = Dataset.from_dict(train_dataset)\n",
    "test_data = Dataset.from_dict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "transformed_train_data = train_data.with_transform(transforms)\n",
    "transformed_test_data = test_data.with_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/usr/local/lib64/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.058294</td>\n",
       "      <td>0.533149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.012815</td>\n",
       "      <td>0.654696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.997576</td>\n",
       "      <td>0.687845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/usr/local/lib64/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9, training_loss=1.0410361819797092, metrics={'train_runtime': 61.7371, 'train_samples_per_second': 36.056, 'train_steps_per_second': 0.146, 'total_flos': 1.724987149196452e+17, 'train_loss': 1.0410361819797092, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"cats_horses_dogs\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=transformed_train_data,\n",
    "    eval_dataset=transformed_test_data,\n",
    "    tokenizer=image_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ds = test_data\n",
    "image = ds[\"image\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.34553518891334534, 'label': 'cat'},\n",
       " {'score': 0.3443831503391266, 'label': 'dog'},\n",
       " {'score': 0.31008172035217285, 'label': 'horse'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"image-classification\", model=\"cats_horses_dogs/checkpoint-9/\")\n",
    "classifier(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
